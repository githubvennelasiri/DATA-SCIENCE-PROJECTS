# -*- coding: utf-8 -*-
"""Loan_Approval_Project_Resume_last.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EDWvh2ybbyJ5fYNIsHjQKUq1Ty0W5aC9

PROBLEM STATEMENT:
LOANS are the major requirement of the modern world.By this only,Banks get a major part of the total profit.It is beneficial for students to manage their education and living expenses, and for people to buy any kind of luxury like houses,cars,etc.But when it comes to deciding whether the applicants profile is relevant to be granted with loan or not.Banks have to look after many aspects. We are going to develop one such model that can predict whether a person will get his/her loan approved or not by using some of the background nformation of the applicant like the applicants gender,marital status,income,etc.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# %matplotlib inline

df = pd.read_csv("/content/Dataset.csv")

df.head()

df.tail()

df.shape

df.columns

df.info()

df.isnull().sum()

# Checking the outliers

plt.figure(figsize=(12,8))
sns.boxplot(data = df)

# Filling the null values of numerical data type
df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].median())
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())
df['Credit_History'] = df['Credit_History'].fillna(df['Credit_History'].mean())

# Filling the null values of object data type
df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])
df['Married'] = df['Married'].fillna(df['Married'].mode()[0])
df['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])
df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])

df.isnull().sum()

print('Number of people Who took loan by Gender')
print(df['Gender'].value_counts())
sns.countplot(x='Gender',data = df, palette='Set2')

print('Number of people Who took loan by Married')
print(df['Married'].value_counts())
sns.countplot(x='Married',data = df, palette='Set1')

print('Number of people Who took loan by Education')
print(df['Education'].value_counts())
sns.countplot(x='Education',data = df, palette='Set3')

corr = df.corr()
plt.figure(figsize=(10,8))
sns.heatmap(corr,annot = True, cmap = 'BuPu')

corr = df.corr()
corr

df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']

df.head()

# Applying Log Transformation

df['ApplicantIncome_Log'] = np.log(df['ApplicantIncome']+1)
sns.distplot(df['ApplicantIncome_Log'])

df['Loan_Amount_Term_Log'] = np.log(df['Loan_Amount_Term']+1)
sns.distplot(df['Loan_Amount_Term_Log'])

df['Total_Income_Log'] = np.log(df['Total_Income']+1)
sns.distplot(df['Total_Income_Log'])

df.head()

# Dropping Unnecessary Features

cols = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Total_Income','Loan_ID']
df = df.drop(columns = cols, axis = 1)
df.head()

# Will do encoding now : Label Encoding
from sklearn.preprocessing import LabelEncoder
cols = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']
le = LabelEncoder()
for col in cols:
  df[col] = le.fit_transform(df[col])

df.head()

df.dtypes

# Splitting Independent And Dependent Fetures

x = df.drop(columns = ['Loan_Status'],axis = 1)
y = df['Loan_Status']

x

y

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state=42)

"""FIRST MODEL : LOGISTIC REGRESSION"""

model1 = LogisticRegression()
model1.fit(x_train,y_train)
y_pred_model1 = model1.predict(x_test)
accuracy = accuracy_score(y_test,y_pred_model1)

accuracy*100

score = cross_val_score(model1,x,y,cv=5)
score

np.mean(score)*100

"""SECOND MODEL : DECISION TREE CLASSIFIER"""

model2 = DecisionTreeClassifier()
model2.fit(x_train,y_train)
y_pred_model2 = model2.predict(x_test)
accuracy = accuracy_score(y_pred_model2,y_test)
print("Accuracy Score Of Decision Tree Model:",accuracy*100)

score = cross_val_score(model2,x,y,cv=5)
print("Cross Validation Score Of Decision Tree Model:",np.mean(score)*100)

"""THIRD MODEL : RANDOM FOREST CLASSIFIER"""

model3 = RandomForestClassifier()
model3.fit(x_train,y_train)
y_pred_model3 = model3.predict(x_test)
accuracy = accuracy_score(y_pred_model3,y_test)
print("Accuracy Score Of Random Forest Classifier is:",accuracy*100)

"""FOURTH MODEL: KNEIGHBOR CLASSIFIER"""

model4 = KNeighborsClassifier(n_neighbors=5)
model4.fit(x_train,y_train)
y_pred_model4 = model4.predict(x_test)
accuracy = accuracy_score(y_pred_model4,y_test)
print("Accuracy Score Of KNeighbor model:",accuracy*100)

score = cross_val_score(model4,x,y,cv=5)
print("Cross Validation Score Of KNeighborsClassifier Model:",np.mean(score)*100)

from sklearn.metrics import classification_report
def generate_classification_report(model_name,y_test,y_pred):
  report = classification_report(y_test,y_pred)
  print(f"Classification Report For {model_name}:\n{report}\n")
generate_classification_report(model1,y_test,y_pred_model1)
generate_classification_report(model2,y_test,y_pred_model2)
generate_classification_report(model3,y_test,y_pred_model3)
generate_classification_report(model4,y_test,y_pred_model4)

pip install -U imbalanced-learn

from imblearn.over_sampling import RandomOverSampler

oversample = RandomOverSampler(random_state=42)
x_resampled, y_resampled = oversample.fit_resample(x,y)

df_resampled = pd.concat([pd.DataFrame(x_resampled,columns=x.columns),pd.Series(y_resampled,name="Loan_Status")],axis=1)

x_resampled

y_resampled

y_resampled.value_counts()

x_resampled_train,x_resampled_test,y_resampled_train,y_resampled_test = train_test_split(x_resampled,y_resampled,test_size = 0.25, random_state=42)

"""FIRST MODEL : LOGISTIC REGRESSION"""

model1 = LogisticRegression()
model1.fit(x_resampled_train,y_resampled_train)
y_pred_model1 = model1.predict(x_resampled_test)
accuracy = accuracy_score(y_resampled_test,y_pred_model1)
print("Accuracy of Logistic Regression Model After retraining a model is:", accuracy*100)

"""SECOND MODEL : DECISION TREE CLASSIFIER"""

model2 = DecisionTreeClassifier()
model2.fit(x_resampled_train,y_resampled_train)
y_pred_model2 = model2.predict(x_resampled_test)
accuracy = accuracy_score(y_pred_model2,y_resampled_test)
print("Accuracy Score Of Decision Tree Model After retraing is:",accuracy*100)

"""THIRD MODEL: RANDOM FOREST CLASSIFIER"""

model3 = RandomForestClassifier()
model3.fit(x_resampled_train,y_resampled_train)
y_pred_model3 = model3.predict(x_resampled_test)
accuracy = accuracy_score(y_pred_model3,y_resampled_test)
print("Accuracy Score Of Random Forest Classifier is:",accuracy*100)

"""FOURTH MODEL: KNEIGHBOR CLASSIFIER"""

model4 = KNeighborsClassifier(n_neighbors=5)
model4.fit(x_resampled_train,y_resampled_train)
y_pred_model4 = model4.predict(x_resampled_test)
accuracy = accuracy_score(y_pred_model4,y_resampled_test)
print("Accuracy Score Of KNeighbor model:",accuracy*100)

from sklearn.metrics import classification_report
def generate_classification_report(model_name,y_test,y_pred):
  report = classification_report(y_test,y_pred)
  print(f"Classification Report For {model_name}:\n{report}\n")
generate_classification_report(model1,y_resampled_test,y_pred_model1)
generate_classification_report(model2,y_resampled_test,y_pred_model2)
generate_classification_report(model3,y_resampled_test,y_pred_model3)
generate_classification_report(model4,y_resampled_test,y_pred_model4)
